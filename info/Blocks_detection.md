Поиск информационных блоков на изображении
=====================

Для задачи нахождения элементов научных статей на изображении использовался набор данных [«PubLayNet»](https://github.com/ibm-aur-nlp/PubLayNet), опубликованный в [2019 году](https://arxiv.org/abs/1908.07836) и содержащий размеченные документы, в которых выделены следующие классы: текст, заголовок, список, таблица и фигура. 

В статье [«Object detection with deep learning: A review»](https://www.elibrary.ru/item.asp?id=41983194) приводится сравнение двадцати двух моделей для решения задачи обнаружения объектов на основе набора данных [Microsoft coco](https://link.springer.com/chapter/10.1007/978-3-319-10602-1_48). Согласно результату, наилучшее качество по метрике средней точности (average precision) показывает архитектура нейронной сети Mask R-CNN с извлечением признаков из изображения при помощи сети ResNeXt [«Aggregated Residual Transformations for Deep Neural Networks»](https://arxiv.org/abs/1611.05431). Плюсом арихектуры Mask R-CNN является то, что она решает задачу instance segmentation –  определение пикселей, принадлежащих каждому объекту каждого класса по отдельности, что позволяет получать высокое качество при сегментации объектов на изображении.

Для реализации нахождения элементов страницы была выбрана программная библиотека [Detectron2](https://github.com/facebookresearch/detectron2). Библиотека Detectron2 содержит в себе архитектуру Mask R-CNN с сетью ResNeXt в качества извлечения признаков.

Метрика средней точности (average precision) полученной модели составила 90,57%. Для обучения модели использовалось 191000 изображений, а для тестирования использовалось 11000 изображений.